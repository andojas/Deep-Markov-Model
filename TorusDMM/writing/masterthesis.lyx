#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{url}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Subsection
Proteins
\end_layout

\begin_layout Subsubsection
Prediction of Structure
\end_layout

\begin_layout Standard
Proteins are essential macromolecules of living organisms 
\begin_inset CommandInset citation
LatexCommand cite
key "pandey2006computational"
literal "false"

\end_inset

.
 While having diverse essential biological functions ranging from DNA replicatio
n, forming cytoskeletal structures, transporting oxygen within multicellular
 organisms, functioning as enzymes and converting one molecule into another
 
\begin_inset CommandInset citation
LatexCommand cite
key "PetersTheodore2005PSaF"
literal "false"

\end_inset

 analysing their threedimensional structure and knowledge of their functions
 is also a crucial information for development of new drugs, better crops
 and even synthetic biofuels.
 Since large scale sequencing-technologies were developed, the availability
 of protein sequence information has been grown exponentially.
 To determine the threedimensional structure of proteins experimental approaches
 are X-ray crystallography or nuclear magnetic resonance.
 The drawback of these methods is that they are expensive in terms of time
 and experimental requirements and not feasible for all proteins 
\begin_inset CommandInset citation
LatexCommand cite
key "pandey2006computational,lee2007predicting"
literal "false"

\end_inset

.
 This is where researchers increasingly rely on computational methods.
 Fully successfull computational methods for protein structure prediction
 are still lacking in order to provide information for the large fraction
 of sequences whose structures are not determined experimentally 
\begin_inset CommandInset citation
LatexCommand cite
key "baker2001protein"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Structure of Proteins
\end_layout

\begin_layout Standard
Proteins are built of a chain of amino acids with varying lengths which
 are joined through peptide bonds.
 The peptide bond is planar.
 There are 20 natural amino acids, that have a common basic structure, with
 a central C
\begin_inset script subscript

\begin_layout Plain Layout
ùõº
\end_layout

\end_inset

-atom, a carboxyl group, an amino group and a side chain R.
 The peptide bond is formed between the carboxyl group of the first amino
 acid and the amino group of the second amino acid, see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:AminoAcidball"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The chain of N-C
\begin_inset script subscript

\begin_layout Plain Layout
ùõº
\end_layout

\end_inset

-C-N-C
\begin_inset script subscript

\begin_layout Plain Layout
ùõº
\end_layout

\end_inset

-C-...
 atoms is called the backbone.
 The amino acids differ from each other through their side chain R.
 The side chains can have variable properties like ability to form hydrogen
 bonds, charge or hydrophobicity 
\begin_inset CommandInset citation
LatexCommand cite
key "PetersTheodore2005PSaF"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
As can be seen in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Protein_folding"
plural "false"
caps "false"
noprefix "false"

\end_inset

 the protein folds into a defined threedimensional structure driven by interacti
ons between side chains, backbone and solvent.
 This particular 3D structure is the basis on which protein binding sides,
 functions, biochemical properties and interaction with other molecules
 can be derived from 
\begin_inset CommandInset citation
LatexCommand cite
key "ingraham2018learning"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/Peptidformationball.png
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Two amino acids with with a central C-atom, a carboxyl group, an amino group
 and a side chain R each forming the peptide bond and releasing one water
 molecule.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:AminoAcidball"

\end_inset

 Retrieved from: https://en.wikipedia.org/wiki/Amino_acid.
 Date of access: 13.05.2019.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/Protein_folding_schematic.png
	lyxscale 30
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Example of protein folding driven by hydrophobic forces.
 In the schematic representation of the folding can be seen that the protein
 is folded so that hydrophobic amino acids (black dots) are shielded from
 the aqueous environment.
 Retrieved from: https://en.wikipedia.org/wiki/Protein_folding.
 Date of access: 13.05.2019.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Protein_folding"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
A protein has three dihedral angles, namely 
\begin_inset Formula $\omega$
\end_inset

, 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\psi$
\end_inset

 between the backbone atomes C-N, N-C
\begin_inset script subscript

\begin_layout Plain Layout
ùõº
\end_layout

\end_inset

 and C
\begin_inset script subscript

\begin_layout Plain Layout
ùõº
\end_layout

\end_inset

-C respectively, as can be depicted in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:3_angles_protein"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The 
\begin_inset Formula $\omega$
\end_inset

 adapts to one of two configuratoins, a value of 0 or 180¬∞.
 The configuration of 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\psi$
\end_inset

 are limitied by unfavourable close contacts with neighboring atoms and
 pose steric constraints in the conformational space.
 The allowed values for 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\psi$
\end_inset

 were first determined by G.
 N.
 Ramachandran.
 The allowed values are indicated in a two-dimensionl plot of 
\begin_inset Formula $\phi$
\end_inset

 against 
\begin_inset Formula $\psi$
\end_inset

 that is called Ramachandran plot after G.
 N.
 Ramachandran who first determinated the allowed values for 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\psi$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "ramachandran1968conformation"
literal "false"

\end_inset

, see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Rama_intro"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The characteristics of a protein can be further described by differing
 bond lengths between the backbone atoms 
\begin_inset CommandInset citation
LatexCommand cite
key "McNaughtAlanD2003ICoc"
literal "false"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "WhitfordDavid2005Psaf"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/Protein_backbone_PhiPsiOmega_drawing.jpg
	lyxscale 40
	scale 20

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Model of the backbone dihedral angles 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\psi$
\end_inset

 (and 
\begin_inset Formula $\omega$
\end_inset

).
 Retrieved from: https://en.wikibooks.org/wiki/Structural_Biochemistry/Proteins/Ra
machandran_Plot.
 Date of access: 14.05.2019.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:3_angles_protein"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Ramachandran Plot
\end_layout

\begin_layout Standard
A Ramachandran Plot showed in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Rama_intro"
plural "false"
caps "false"
noprefix "false"

\end_inset

 shows the sterically inhibited regions in white, the regions without any
 steric clashes in red which are namely the alpha-helical and beta-sheet
 conformations.
 The yellow regions show allowed regions of limited stability, the let handed
 alpha helix 
\begin_inset CommandInset citation
LatexCommand cite
key "WhitfordDavid2005Psaf"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/Rama_intro.gif
	lyxscale 50
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Example of a Ramachandran Plot of a Protein visualiszing the dihedral angles
 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\psi$
\end_inset

 of a Protein.
 Retrieved from: http://www.cryst.bbk.ac.uk/PPS95/course/3_geometry/rama.html.
 Date of access: 14.05.2019.
\begin_inset CommandInset label
LatexCommand label
name "fig:Rama_intro"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Prediction methods and CASP
\end_layout

\begin_layout Standard
Protein structure prediction is still an unsolved problem which is approached
 by many research groups.
 To evaluate and assess different modelling approaches a scientific biennial
 competition called Critical Assessment of Protein Structures (CASP).
 In every CASP participants attempt to computationally model the 3D structures
 of proteins of which the structure has been solved experimentally already
 but it has not been released publically 
\begin_inset CommandInset citation
LatexCommand cite
key "moult1995large"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
The protein prediction techniques where no template comparison or evolutionary
 information is used and the fold is predicted on the amino acid sequence
 only is called 
\shape italic
ab initio
\shape default
.
 The first principle-based 
\shape italic
ab initio
\shape default
 approaches start with an unfolded conformation and simulate physical forces
 to fold the protein into its 3D structure.
\end_layout

\begin_layout Subsection
Machine Learning
\end_layout

\begin_layout Section
Material and Methods
\end_layout

\begin_layout Subsection
Bayes‚Äô Theorem
\end_layout

\begin_layout Standard
Bayesian Statistics is a probabilistic approach to statistical inference.
 The fundamental difference to the more commonly known Frequentism is that
 instead of obtaining a singular value one is provided with a distribution,
 called the posterior (distribution) 
\begin_inset CommandInset citation
LatexCommand cite
key "vanderplas2014frequentism"
literal "false"

\end_inset

.
 The posterior contains a range of values with corresponding probabilities
 for each value, from which a single sample can be drawn.
 It is based on Bayes' theorem,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(z|x)=\frac{p(x|z)p(z)}{p(x)}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $z$
\end_inset

 represents the latent random variables and 
\begin_inset Formula $x$
\end_inset

 represents the observation.
 The posterior distribution 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $p(z|x)$
\end_inset

 is given by the likelihood 
\begin_inset Formula $p(x|z)$
\end_inset

 times the prior 
\begin_inset Formula $p(z)$
\end_inset

 divided by the normalization constant 
\begin_inset Formula $p(x)$
\end_inset

.
 The normalization constant 
\begin_inset Formula $p(x)$
\end_inset

 is often untracable.
 Which leads to the assumption that 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset CommandInset citation
LatexCommand cite
key "hamelryck2012bayesian"
literal "false"

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(z|x)\propto p(x|z)p(z)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
posterior\propto likelihood\times prior
\]

\end_inset


\end_layout

\begin_layout Subsection
Hidden Markov Model
\end_layout

\begin_layout Standard
A hidden Markov model (HMM) is a markov chain of latent variables from which
 observed variables can be obtained.
 A sequence of events is generated.
 The latent variable 
\begin_inset Formula $z_{i}$
\end_inset

 is conditioned on the previous 
\begin_inset Formula $z_{i-1}$
\end_inset

, so it is governed by the transition probability 
\begin_inset Formula $p(z_{i}|z_{i-1})$
\end_inset

.
 The observed variables 
\begin_inset Formula $x_{i}$
\end_inset

 are conditioned on the respective 
\begin_inset Formula $z_{i}$
\end_inset

 and they are governed by the emission probability 
\begin_inset Formula $p(x_{i}|z_{i})$
\end_inset

 as can be seen in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:HMM"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 This way the model can represent complex time dependencies.
 The latent states are not directly observable thus they are regarded as
 hidden and it is called a 
\shape italic
hidden
\shape default
 markov model 
\begin_inset CommandInset citation
LatexCommand cite
key "hmm1Kroghbook"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Hidden Markov models quickly became popular as a tool for supervised machine
 learning and they are now commonly used for sequence analysis 
\begin_inset CommandInset citation
LatexCommand cite
key "hmm2"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/HMM.png
	lyxscale 40
	scale 20

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Hidden Markov Model with latent states 
\begin_inset Formula $z$
\end_inset

 and observed states 
\begin_inset Formula $x$
\end_inset

.
 Transition probabilites govern the latentn variables 
\begin_inset Formula $z$
\end_inset

 and emission probabilites govern 
\begin_inset Formula $x$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig:HMM"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Neural Networks
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "machinelearningbookbaldi2001"
literal "false"

\end_inset

 Neural networks (NNs) were initially developed in analogy to neurons as
 a model for information processing and learning in the brain.
 NNs are paramterized graphical models with interconnected units.
 The connection between two units 
\begin_inset Formula $j$
\end_inset

 and 
\begin_inset Formula $i$
\end_inset

 is denoted by a weight 
\begin_inset Formula $w_{ij}.$
\end_inset

 A NN can be seen as a weight directed graph.
\end_layout

\begin_layout Standard
Architectures of neural networks are feedforward, recurrent and layered.
 In the context of this project layered feedforward and recurrent NNs are
 used.
 As can be seen in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:NN"
plural "false"
caps "false"
noprefix "false"

\end_inset

 mulitlayer feedforward NNs consist of multiple layers with visible input
 and output layers and multiple hidden layers.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/NN.png
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Neural Network with input layer, two hidden layers and output layer.
 Retrieved from https://chatbotslife.com/how-neural-networks-work-ff4c7ad371f7.
 Date of access: 22.03.2019 
\begin_inset CommandInset label
LatexCommand label
name "fig:NN"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
A recurrent neural network (RNN) has at least one feedback loop, that means
 neurons can feed its output signal back to the inputs of other neurons.
 It has a profound impact on the learning capability and the performance
 of the network 
\begin_inset CommandInset citation
LatexCommand cite
key "NNbookhaykin1994"
literal "false"

\end_inset

.
 In the scope of this project a RNN with one hidden layer is used.
\end_layout

\begin_layout Subsubsection
Activation Functions
\end_layout

\begin_layout Standard
Activation functions are the nonlinear units in neural networks and determine
 the output behaviour of the nodes.
 In order to predict posterior probabilities that lie in range of 0 and
 1 the weight 
\begin_inset Formula $w_{ij}$
\end_inset

 which is a linear function is transformed using a nonlinear function that
 is called activation function.
 There are different forms of activation functions 
\begin_inset CommandInset citation
LatexCommand cite
key "BishopChristopherM2006Pram"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection*
Sigmoid Function
\end_layout

\begin_layout Standard
The sigmoid function also called logistic sigmoid function is defined by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Sigmoid(x)=\frac{1}{1+\exp(-x)}
\]

\end_inset


\end_layout

\begin_layout Standard
It maps the whole real axis into a finite interval.
\end_layout

\begin_layout Subsubsection*
Softmax Function
\end_layout

\begin_layout Standard
The softmax function is known as the normalized exponential and can be regarded
 as a multiclass generalisation of the logistic sigmoid.
 It is defined by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Softmax(x_{i})=\frac{\exp(x_{i})}{\sum_{j}\exp(x_{j})}
\]

\end_inset


\end_layout

\begin_layout Standard
It is used in classification cases with more than two classes.
 The softmax function is indivually applied to evey input element.
 After application all elements sum to 1 
\begin_inset CommandInset citation
LatexCommand cite
key "BishopChristopherM2006Pram"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection*
Rectified Linear Unit Function
\end_layout

\begin_layout Standard
The Rectified Linear Unit (ReLU) is described by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
ReLU(x)=\max(0,x)
\]

\end_inset


\end_layout

\begin_layout Standard
Applied to 
\begin_inset Formula $x$
\end_inset

 negative values become 0 wheareas positive numbers it returns back that
 value 
\begin_inset CommandInset citation
LatexCommand cite
key "lecun2015deep"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Distributions
\begin_inset CommandInset label
LatexCommand label
name "subsec:Distributions"

\end_inset


\end_layout

\begin_layout Standard
In the DMM two distributions are used to sample amino acids and angles.
 For the amino acids a von Mises distribution is used, for the amino acids
 an one hot categorical distribution.
\end_layout

\begin_layout Subsubsection*
Von Mises Distribution
\end_layout

\begin_layout Standard
The von Mises distribution is a continuous normal distribution on a circle
 and the most prominent among the univariate circular distributions.
 The probability density function for the angle 
\begin_inset Formula $x$
\end_inset

 is given by 
\begin_inset Formula 
\[
f(x|\mu,\kappa)=\frac{e^{\kappa\cos(x-\mu)}}{2\pi I_{0}(\kappa)}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $I_{0}(\kappa)$
\end_inset

 is the modified Bessel function of order p.
 The parameters 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\frac{1}{\kappa}$
\end_inset

 are equivalents of the mean 
\begin_inset Formula $\mu$
\end_inset

 and the variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

 in the normal distribution.
 
\begin_inset Formula $\kappa$
\end_inset

 is a measure of concentration.
 As can be seen in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:vonMises"
plural "false"
caps "false"
noprefix "false"

\end_inset

 it means that for 
\begin_inset Formula $\kappa$
\end_inset

 equal to zero or being very small the distribution is uniform or close
 to uniform.
 For large 
\begin_inset Formula $\kappa$
\end_inset

 the distribution becomes very concentrated at the angle 
\begin_inset Formula $\mu$
\end_inset

 with 
\begin_inset Formula $\kappa$
\end_inset

 being a measure of concentration 
\begin_inset CommandInset citation
LatexCommand cite
key "vonmisesbest1979,vonmisesmardia2008"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/VonMises_distribution_PDF.png
	lyxscale 30
	scale 13

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Plot of the von Mises distribution with different 
\begin_inset Formula $k$
\end_inset

.
 Retrieved from https://en.wikipedia.org/wiki/Von_Mises_distribution.
 Date of access: 22.03.2019.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:vonMises"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
One hot Categorical
\end_layout

\begin_layout Standard
The amino acids where sampled using a one hot categorical distribution,
 in order to avoid any ranking of the aminoacids.
\end_layout

\begin_layout Subsection
Pyro and probabilistic programming
\end_layout

\begin_layout Standard
The model was implemented in Pyro, a deep probabilistic programming language
 written in Python and based on the framework PyTorch 
\begin_inset CommandInset citation
LatexCommand cite
key "bingham2018pyro"
literal "false"

\end_inset

.
 A deep probabilistic programming language combines deep neural networks
 and probabilistic models.
 Deep learning is automatic hierarhical and supervised representation learning.
 They enable including Bayesian statistics and making probabilistic assumptions
 in powerful machine-learning applications and in this way also representing
 uncertainty.
 Output data is generated by sampling from a latent probability distribution.
 The model is trained upon an inference procedure which uses observed output
 data to fit the latent distribution 
\begin_inset CommandInset citation
LatexCommand cite
key "baudart2018deep"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
In figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Model_Graphical"
plural "false"
caps "false"
noprefix "false"

\end_inset

 a graphical model represents the general structure.
 
\begin_inset Formula $N$
\end_inset

 is the number of observed datapoints 
\begin_inset Formula $\{x_{i}\}$
\end_inset

.
 As it is a generative model, every datapoint is generated by a local random
 variable 
\begin_inset Formula $z_{i}$
\end_inset

.
 
\begin_inset Formula $\theta$
\end_inset

 is a global parameter because all datapoints depend on it [this paragraph
 is not finished yet.
 I m still writing on it]
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/VAE1.png
	scale 25

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Graphical Representation 
\begin_inset CommandInset label
LatexCommand label
name "fig:Model_Graphical"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Deep Markov Model
\end_layout

\begin_layout Standard
The model used for predicting the protein structure is a Deep (hidden) Markov
 Model (DMM) retrieved from the deep probabilistic programming framework
 Pyro 
\begin_inset CommandInset citation
LatexCommand cite
key "bingham2018pyro"
literal "false"

\end_inset

.
 A DMM is a fusion of a HMM with NNs in between the nodes.
 The structure can be seen in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:DeepHMM"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The nodes are represented by cirlces, 
\begin_inset Formula $z_{0}$
\end_inset

 is the initial state and the black squares represent neural networks.
 An observation of length three is shown 
\begin_inset Formula $\{x_{1},x_{2},x_{3}\}$
\end_inset

 corresponding to a sequence of latent variables 
\begin_inset Formula $\{z_{1},z_{2},z_{3}\}$
\end_inset

.
 The joint distribution is:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p(x_{123},z_{123})=p(x_{1}|z_{1})p(x_{2}|z_{2})p(x_{3}|z_{3})p(z_{1})p(z_{2}|z_{1})p(z_{3}|z_{2})
\]

\end_inset


\end_layout

\begin_layout Standard
The observations 
\begin_inset Formula $x$
\end_inset

 are independet fromfigure each other and only depend on the latent variable
 
\begin_inset Formula $z_{t}$
\end_inset

 at the current timestep.
 The markov property of the model can also be seen: each latent 
\begin_inset Formula $z_{t}$
\end_inset

is conditioned on its previous 
\begin_inset Formula $z_{t-1}$
\end_inset

but independent of all previous latent states 
\begin_inset Formula $\{z_{t-2},z_{t-3},...\}$
\end_inset

.
 The latent variables 
\begin_inset Formula $z$
\end_inset

 are called the latent space.
 The first 
\begin_inset Formula $z_{1}$
\end_inset

 is conditioned on 
\begin_inset Formula $z_{0}$
\end_inset

 is a trainable parameter.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename figures/DMM.png
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Deep Markov Model for three time steps with latent variables 
\begin_inset Formula $z$
\end_inset

, observed variables 
\begin_inset Formula $x$
\end_inset

 and Neural Networks (black squares) in between the nodes.Sigmoid Function
\begin_inset CommandInset label
LatexCommand label
name "fig:DeepHMM"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In our specific case the observed variables 
\begin_inset Formula $x$
\end_inset

 are the mean of the the of the observed angles 
\begin_inset Formula $\mu_{\phi}$
\end_inset

 and 
\begin_inset Formula $\mu_{\psi}$
\end_inset

 of the dihedral angles 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\varphi$
\end_inset

 of the protein and the 
\begin_inset Formula $\kappa_{\phi}$
\end_inset

 and 
\begin_inset Formula $\kappa_{\psi}$
\end_inset

 as well as the amino acids 
\begin_inset Formula $aa$
\end_inset

 at every specific timestep 
\begin_inset Formula $t$
\end_inset

, see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:DMM_spec"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 For simplicity the bond lengths between the atoms are considered constant.
 The third angle 
\begin_inset Formula $\omega$
\end_inset

 was not considered in the model.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/dmm_specific.png
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Deep Markov Model for three timesteps with latent variabls 
\begin_inset Formula $z$
\end_inset

 and observed variables for amino acids 
\begin_inset Formula $aa$
\end_inset

, for the means 
\begin_inset Formula $\mu_{\phi}$
\end_inset

 and 
\begin_inset Formula $\mu_{\psi}$
\end_inset

 and for the variation 
\begin_inset Formula $\kappa_{\phi}$
\end_inset

 and 
\begin_inset Formula $\kappa_{\psi}$
\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:DMM_spec"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The observation likelihoods, the probability distributions which control
 the observations of the mean of the angles 
\begin_inset Formula $p(\mu_{\phi,t}|z_{t})$
\end_inset

 and 
\begin_inset Formula $p(\mu_{\psi,t}|z_{t})$
\end_inset

 and the variances 
\begin_inset Formula $p(\kappa{}_{\phi,t}|z_{t})$
\end_inset

 and 
\begin_inset Formula $p(\kappa_{\psi,t}|z_{t})$
\end_inset

 are von Mises distributions, which as explained in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Distributions"
plural "false"
caps "false"
noprefix "false"

\end_inset

 is used to describe angles.
 For the amino acids 
\begin_inset Formula $p(aa_{t}|z_{t})$
\end_inset

 one hot categorical distributions for which the PyTorch implementation
 is used 
\begin_inset CommandInset citation
LatexCommand cite
key "paszke2017automatic"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Neural Networks
\end_layout

\begin_layout Standard
The black solid squares represent the non-linearities in the model.
 There are two different kind of NNs.
 Transitional NNs ('Trans' in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:DMM_spec"
plural "false"
caps "false"
noprefix "false"

\end_inset

) controls the dynamic of the latent variables and Emitter NNs ('Emit' in
 Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:DMM_spec"
plural "false"
caps "false"
noprefix "false"

\end_inset

) control the how the observations depend on the latent dynamics.
\end_layout

\begin_layout Standard
The NNs make our model a 'deep' markov model and allow to capture complex
 dynamics.
 It can be destinguished between the part of linear transformations and
 the part of nonlinear activation function.
\end_layout

\begin_layout Subsubsection*
Emitter NN
\end_layout

\begin_layout Standard
The emitter NN is a forward NN with four hidden layers and a dimension of
 100.
 The latent state 
\begin_inset Formula $z_{t}$
\end_inset

 is the input.
 ReLU is used as an activation function except for the last nonlinear transforma
tion of the probability of the mean 
\begin_inset Formula $\mu$
\end_inset

 where sigmoid is used and the amino acids where softmax is used.
\end_layout

\begin_layout Subsubsection*
Transition NN
\end_layout

\begin_layout Standard
The transition NN is a gated transition function.
 The architecture is different to the emitter NN because the output are
 the mean and the variance which are required to define a gaussian distribution.
 Also, they both need to have the same dimension as the latent space.
 The mean is a sum of two terms of which only one depends non-linearily
 on the input.
 This makes it possible to support both linear and nonlinear dynamics, so
 part of the dynamic of the latent space can be linear while the remainder
 can stay nonlinear.
\end_layout

\begin_layout Subsubsection*
Gradient Descent
\end_layout

\begin_layout Standard
[here I still have to write something]
\end_layout

\begin_layout Subsubsection
Model
\end_layout

\begin_layout Standard
In the model we first sample 
\begin_inset Formula $z_{1}$
\end_inset

 that is conditioned on 
\begin_inset Formula $z_{0}$
\end_inset

 which is a trainable parameter.
 Once we have sampled 
\begin_inset Formula $z_{1}$
\end_inset

 we can sample 
\begin_inset Formula $z_{2}\sim p(z_{2}|z_{1})$
\end_inset

 and so on.
 For sampling all 
\begin_inset Formula $z$
\end_inset

 a for-loop is implemented.
 The probability distribution 
\begin_inset Formula $p(z_{t}|z_{t-1})$
\end_inset

 is defined by the parameters of the mean and variance which are called
 'z_loc' and 'z_scale' in pyro.
 They are computed at a specific timestep 
\begin_inset Formula $t$
\end_inset

 using the transition NN and are conditioned on the previous timestep 
\begin_inset Formula $t-1$
\end_inset

.
\end_layout

\begin_layout Standard
Once 
\begin_inset Formula $z_{t}$
\end_inset

 is sampled at a specific timestep, we need to observe the datapoint 
\begin_inset Formula $x_{t}$
\end_inset

.
 Therfor, 
\begin_inset Formula $z_{t}$
\end_inset

 is passed through the emitter NN and the probability for the 
\begin_inset Formula $aa$
\end_inset

 and the mean 
\begin_inset Formula $\mu$
\end_inset

 and the variance 
\begin_inset Formula $\kappa$
\end_inset

 are output.
 Using the von Mises distribution and 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\kappa$
\end_inset

 the angles are sampled for 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\psi$
\end_inset

 and a one-hot categorical distribution is used for sampling the amino acids.
\end_layout

\begin_layout Standard
The posterior of the model, the probability of the parameters of the NNs
 
\begin_inset Formula $\theta$
\end_inset

 and the probability of the latent variable 
\begin_inset Formula $z$
\end_inset

 conditioned on the data 
\begin_inset Formula $x$
\end_inset

 is defined by equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:posterior1_model"
plural "false"
caps "false"
noprefix "false"

\end_inset

, the likelihood of the data 
\begin_inset Formula $x$
\end_inset

 conditioned on the parameters 
\begin_inset Formula $\theta$
\end_inset

 and 
\begin_inset Formula $z$
\end_inset

 times the prior of 
\begin_inset Formula $\theta$
\end_inset

 times the prior of 
\begin_inset Formula $z$
\end_inset

.
 
\begin_inset Formula $z$
\end_inset

 is estimated by approximating the posterior, using Bayesian Statistics,
 whereas the estimation of 
\begin_inset Formula $\theta$
\end_inset

 is a point estimation and not bayesian in this model.
 Ideally the estimation of 
\begin_inset Formula $\theta$
\end_inset

 would also be defined by a posterior distribution.
 However having several NNs with multiple layers, being bayesian about 
\begin_inset Formula $\theta$
\end_inset

 would not be computationally feasible at this point.
\end_layout

\begin_layout Standard
Following this, the posterior is approximated by equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:posterior2_model"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
p(\theta,z|x)\propto p(x|\theta,z)p(\theta)p(z)\label{eq:posterior1_model}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
p(\theta,z|x)\thickapprox p_{\theta}(x|z)p(z)\label{eq:posterior2_model}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Inference
\begin_inset CommandInset label
LatexCommand label
name "subsec:Inference"

\end_inset


\end_layout

\begin_layout Standard
Stochastic Variational Inference (SVI) was used as an inference method.
 A variational lower bound is optimised to approximate the data log-likelihood
 because the exact posterior is intractable.
\end_layout

\begin_layout Standard
The model has the probability density function 
\begin_inset CommandInset citation
LatexCommand cite
key "pyroSVI1"
literal "false"

\end_inset

:
\begin_inset Formula 
\[
p_{\theta}(x,z)=p_{\theta}(x|z)p_{\theta}(z)
\]

\end_inset


\end_layout

\begin_layout Standard
It is assumed that 
\begin_inset Formula $p_{\theta}(x,z)$
\end_inset

 consists of various probability distributions 
\begin_inset Formula $p_{i}$
\end_inset

.
 
\begin_inset Formula $\theta$
\end_inset

 describes the parameter space of the model.
 To find 
\begin_inset Formula $\theta$
\end_inset

 that describes the model best, the log evidence is maximised:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\theta_{\max}=\underset{\theta}{\arg\max}\log p_{\theta}(x)
\]

\end_inset


\end_layout

\begin_layout Standard
The log evidence is given by the integral over the joint probability function:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log p_{\theta}(x)=\log\int p_{\theta_{\max}}(x,z)\,dz
\]

\end_inset


\end_layout

\begin_layout Standard
The integral is unavailable in closed form or requires exponential time
 to compute, but it is the denominator of the posterior which we also want
 to compute:
\begin_inset Formula 
\[
p_{\theta_{\max}}(z|x)=\frac{p_{\theta_{\max}}(x,z)}{\int p_{\theta_{\max}}(x,z)\,dz}
\]

\end_inset


\end_layout

\begin_layout Standard
That is why the posterior 
\begin_inset Formula $p_{\theta_{\max}}(z|x)$
\end_inset

 is approximated by a guide 
\begin_inset Formula $q_{\phi}(z)$
\end_inset

 which is a paramterized distribution with variational parameters 
\begin_inset Formula $\phi$
\end_inset

.
 Since the guide is an approximation to the posterior 
\begin_inset Formula $p_{\theta_{\max}}(z|x)$
\end_inset

 it needs to provide a valid joint probability density over the latent space.
 As described by Blei, Kucukelbir and McAuliffe 
\begin_inset CommandInset citation
LatexCommand cite
key "blei2017variational"
literal "false"

\end_inset

 an optimization problem is set up by finding the guide which is closest
 to the posterior.
 An appropriate objective function has to be defined: the 
\begin_inset Formula $ELBO$
\end_inset

: 
\bar under
e
\bar default
vidence 
\bar under
l
\bar default
ower 
\bar under
bo
\bar default
und:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
ELBO\equiv\mathbb{E}_{q_{\phi}(z)}[\log p_{\theta}(x,z)-\log q_{\phi}(z)]
\]

\end_inset


\end_layout

\begin_layout Standard
By assumption the log probabilites indside the expectation function can
 be computed.
 The 
\begin_inset Formula $ELBO$
\end_inset

 is a lower bound to the log evidence and can never become bigger than the
 log evidence.
 In an ideal case it would be equal to the log evidence: 
\begin_inset Formula 
\[
\log p_{\theta}(x)\geq ELBO
\]

\end_inset


\end_layout

\begin_layout Standard
The gap between the 
\begin_inset Formula $ELBO$
\end_inset

 and the log evidence is given by the Kullback-Leibler (KL) divergence 
\begin_inset CommandInset citation
LatexCommand cite
key "pyroSVI1,bingham2018pyro"
literal "false"

\end_inset

, a measure of the difference between two probability distributions 
\begin_inset CommandInset citation
LatexCommand cite
key "Kullback-Leibler"
literal "false"

\end_inset

, between the guide and the posterior:
\begin_inset Formula 
\[
\log p_{\theta}(x)-ELBO=KL(p_{\theta}(z|x)\Vert q_{\phi}(z))
\]

\end_inset


\end_layout

\begin_layout Standard
It can be seen, that the bigger the 
\begin_inset Formula $ELBO$
\end_inset

 becomes the closer it will be to the log evidence and the better the approximat
ion.
 Hence we want to maximize the 
\begin_inset Formula $ELBO$
\end_inset

 and an optimization problem is created.
 The smaller the KL divergence betweent the posterior 
\begin_inset Formula $p_{\theta}(z|x)$
\end_inset

 and the guide 
\begin_inset Formula $q_{\phi}(z)$
\end_inset

 the better the approximation is 
\begin_inset CommandInset citation
LatexCommand cite
key "pyroSVI1,bingham2018pyro"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Using variational inference, the sampling problem is transferred into an
 optimization problem 
\begin_inset CommandInset citation
LatexCommand cite
key "blei2017variational"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Guide
\end_layout

\begin_layout Standard
As explained in chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Inference"
plural "false"
caps "false"
noprefix "false"

\end_inset

, the purpose of the guide which is given by the variational distribution
 is to provide a parameterised approximation to the exact posterior 
\begin_inset Formula $p(z_{1:T}|x_{1:T})$
\end_inset

.
 The size of the parameters 
\begin_inset Formula $\theta$
\end_inset

 is very high even for small N.
 It has to describe a very high-dimensional distribution to approximate
 the posterior.
 To make this enormous growth of the dataset possible amortisation is used.
\end_layout

\begin_layout Subsubsection*
Amortization
\end_layout

\begin_layout Standard
The space which is optimised grows with the number of sequences N which
 makes calculating local variational parameters for every 
\begin_inset Formula $z_{i}$
\end_inset

 problematic.
 Instead amortization is used which learns a single parametric function
 
\begin_inset Formula $f\left(\cdot\right)$
\end_inset

.
 It is sharing one global parameter 
\begin_inset Formula $\theta$
\end_inset

 across all datapoints 
\begin_inset Formula $q(z_{i})$
\end_inset

 instead of multiple local parameters so that the guide is given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
q(z,\beta)=q(\beta)\stackrel[n=1]{N}{\prod}q(z_{i}|f(x_{i}))
\]

\end_inset


\end_layout

\begin_layout Standard
In order to construct a parametric function 
\begin_inset Formula $f\left(\cdot\right)$
\end_inset

 that supports different sequence lenghts a recurrent neural network (RNN)
 was implemented as part of the guide.
 In figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:guide"
plural "false"
caps "false"
noprefix "false"

\end_inset

 a graphical representation of the guide is shown.
 
\begin_inset Formula $\{x_{1},x_{2},x_{3}\}$
\end_inset

 at the bottom of the figure are the observations which are the inputs from
 right to the left to the RNN.
 The RNN outputs hidden states 
\begin_inset Formula $\{h_{1},h_{2},h_{3}\}$
\end_inset

 which are together with the previous latent state 
\begin_inset Formula $z_{t-1}$
\end_inset

 the input to the combiner.
 The combiner outputs the mean and the variance of the conditional distribution
 
\begin_inset Formula $q(z_{t}|z_{t-1},x_{t:T})$
\end_inset

 which have to be in the form of a gaussion distribution.
 Only for timestep 
\begin_inset Formula $t=1$
\end_inset

 
\begin_inset Formula $z_{1}$
\end_inset

 is conditioned on a trainable variational parameter 
\begin_inset Formula $z_{0}^{q}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/guide.png
	lyxscale 40
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The guide rolled out for T=3 time steps with the observation 
\begin_inset Formula $\{x_{1},x_{2},x_{3}\}$
\end_inset

, the hidden states 
\begin_inset Formula $\{h_{1},h_{2},h_{3}\}$
\end_inset

, the latent variables 
\begin_inset Formula $\{z_{1},z_{2},z_{3}\}$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig:guide"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Training
\end_layout

\begin_layout Standard
The model was trained on a GeForce GTX 1080 Graphics Card.
 In order to run on GPU the parameter of the model had to be made GPU compatible
 and had to be loaded onto the GPU server.
 For training the dataset is partitioned into mini-batches.
 The order of the sequences is shuffled during training to keep the learning
 general.
\end_layout

\begin_layout Standard
As an optimizer adam optimizer is used which includes gradient clipping
 in order to avoid problems like vanishing or explodeing gradients that
 can typically occur during training.
\end_layout

\begin_layout Standard
The stochastic variational inference uses a stochastic gradient estimator
 to take gradient steps on an objective function.
 The objective function which is the ELBO cannot be computed analytically
 so the parameters will be updated following Monte Carlo gradient estimates.
 The ELBO is the lower bound to the log evidence 
\begin_inset Formula $\log p(D)$
\end_inset

.
 Every step being taken that maximizes the ELBO moves the guide 
\begin_inset Formula $q\left(\cdot\right)$
\end_inset

 closer to the exact posterior.
 The ELBO has probability involved, therefore it is hard to compute the
 gradient estimator.
 Automatic differentiation and full reparameterization for all latent variables
 throughout the model is used in pyro.
\end_layout

\begin_layout Subsubsection*
KL annealing
\end_layout

\begin_layout Standard
As another optimization strategy KL annealing was used.
 As explained in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Inference"
plural "false"
caps "false"
noprefix "false"

\end_inset

 the ELBO is part of the variational inference and it consists of the following
 two terms:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
ELBO=\mathbb{E}_{q(z_{1:T})}[\log p(x_{1:T}|z_{1:T})]-\mathbb{E}_{q(z_{1:T})}[\log q(z_{1:T})-\log p(z_{1:T})]
\]

\end_inset


\end_layout

\begin_layout Standard
The expectation of the log likelihood which measures the model fit in the
 first term and the second term being the KL divergence term which serves
 to regularize the approximate posterior.
\end_layout

\begin_layout Standard
The later term can be a quite strong regularizer and especially in the early
 stages of training it tends to favor regions of the loss surface that contain
 lots of bad local optima.
 To avoid these bad local optima the KL divergence terms are annealed by
 multiplying them with the annealing factor which is a scalar that ranges
 between zero and one, as it was also applied in reference 
\begin_inset CommandInset citation
LatexCommand cite
key "krishnan2017structured"
literal "false"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
ELBO=\mathbb{E}_{q(z_{1:T})}[\log p(x_{1:T}|z_{1:T})]-annealingfactor\times\mathbb{E}_{q(z_{1:T})}[\log q(z_{1:T})-\log p(z_{1:T})]
\]

\end_inset


\end_layout

\begin_layout Standard
The annealing factor is set to a very low value near to zero at the beginning
 of the training and then rises to its final value 1 during the course of
 training.
 The number of epochs which were influenced by the annealing factor was
 set to 1000 epochs.
 That means that starting with zero over the range of 1000 epochs the annealing
 factor rose in a linear way to 1.
\end_layout

\begin_layout Subsubsection
Normalization Flows
\end_layout

\begin_layout Standard
The approximations of the posterior distribution are constructed using normaliza
tion flows which transforms a simple initial density into a more complex
 one by applying a sequence of invertible transformations until a desired
 level of complexity is attained.
 The performance of the posterior approximation is improved by deep auto-regress
ive networks that use an auto-regressive dependency structure.
 Performing inference with normalization flows provides a tighter, modified
 variational lower bound (ELBO) 
\begin_inset CommandInset citation
LatexCommand cite
key "rezende2015variational"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Data and Loading
\end_layout

\begin_layout Standard
The dataset was retrieved from MolProbity which is a protein database of
 high quality structures (source: http://kinemage.biochem.duke.edu/databases/top500.
php, date of access: 29.03.2019).
 The dataset called 
\begin_inset Quotes eld
\end_inset

top500
\begin_inset Quotes erd
\end_inset

 consists of 500 protein sequences and was reduced to a dataset of 402 proteins
 not including sequences with chain breaks or that caused errors upon parsing.
 From this dataset a textfile including the phi and psi angles and the amino
 acid was created which was used as input to the model.
\end_layout

\begin_layout Standard
The protein data loader is a script that is preprocessing the data for the
 DMM.
 The amino acids were encoded using a one hot categorical distribution.
 The dataset was divided into minibatches of varying sizes.
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Subsection
Modelling with Categorical encoding for amino acids (DMM One Hot)
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Reference_Rama"
plural "false"
caps "false"
noprefix "false"

\end_inset

 shows the Ramachandran Plot created by the protein dataset.
 The 
\begin_inset Formula $\phi$
\end_inset

 angles are plotted on the x-axis and the 
\begin_inset Formula $\psi$
\end_inset

 angles are plotted on the y-axis.
 An accumulation of angles can be seen at the top left corner, in the lower
 left quadrant and on the right-hand side which represents according to
 the sterically possible configurations beta-sheets, right-handed alpha
 helixes and left-handed alpha helixes, compare with Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Rama_intro"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Rama_best"
plural "false"
caps "false"
noprefix "false"

\end_inset

 results can be seen from modelling the 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\psi$
\end_inset

 angles with the HMM.
 It can be seen that results are approximating expected results when compared
 to Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Reference_Rama"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The accumulations of the beta-sheet in the top left corner and the accumulation
 for the right-handed alpha helix in the bottom left corner are approximately
 predicted as expected when comparing Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Reference_Rama"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Rama_best"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The accumulation of angles in the right handside of the Ramachandran plot
 is only vaguely approximated by the model.
\end_layout

\begin_layout Standard
In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:ELBO_best"
plural "false"
caps "false"
noprefix "false"

\end_inset

 the negative ELBO can be seen converging.
 It can be seen that the model was stopped and restarted twice after 
\begin_inset Formula $1000$
\end_inset

 iterations and a second time after 
\begin_inset Formula $5000$
\end_inset

 iterations.
 The impact of the annealing factor on the ELBO for 
\begin_inset Formula $1000$
\end_inset

 iterations after starting the model can be seen.
\end_layout

\begin_layout Standard
In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:means_best"
plural "false"
caps "false"
noprefix "false"

\end_inset

 the sampled means of the protein angls are shown.
 It can be seen that the means correlate with the sampled angles in Figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Rama_best"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /home/amelie/Desktop/TorusDMM/writing/figures/StandardRama.png
	lyxscale 45
	scale 45

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Ramachandran plot created by the data set
\begin_inset CommandInset label
LatexCommand label
name "fig:Reference_Rama"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset VSpace defskip
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/Rama_best.png
	lyxscale 30
	scale 45

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Ramachandran plot created by HMM
\begin_inset CommandInset label
LatexCommand label
name "fig:Rama_best"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align right
\begin_inset Graphics
	filename figures/ELBO_best.png
	lyxscale 30
	scale 45

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
The negative ELBO of HMM
\begin_inset CommandInset label
LatexCommand label
name "fig:ELBO_best"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /home/amelie/Desktop/dmm2_3/Means_3950.png
	lyxscale 45
	scale 45

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
rtzrzrtzrztrtrzrttzrtzrtzt 
\begin_inset CommandInset label
LatexCommand label
name "fig:means_best"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Ramachandran plots created by the the 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\psi$
\end_inset

 angles of the 402 amino acid sequences and results
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Limiting 
\begin_inset Formula $\kappa$
\end_inset


\end_layout

\begin_layout Standard
Limiting the variance of the von Mises distribution of the angles 
\begin_inset Formula $\kappa$
\end_inset

 resulted in
\end_layout

\begin_layout Subsection
Modelling with One Hot encoding for amino acids
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="7" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Model
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
time per iteration
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
number of iterations
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
total training time
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DMM_best
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sim48$
\end_inset

 sec.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
119 h
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DMM 4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sim57$
\end_inset

 sec.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6368
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
101 h
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DMM 5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sim374$
\end_inset

 sec.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1695
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
176 h
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DMM_1k
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sim516$
\end_inset

 sec.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1461
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
209 h
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DMM_k12
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sim545$
\end_inset

 sec.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
660
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
100 h
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DMM_one_hot
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sim358$
\end_inset

 sec.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2149
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
214 h
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/StandardRama.png
	lyxscale 30
	scale 23

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/ELBO_best.png
	lyxscale 30
	scale 23

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/Rama_best.png
	lyxscale 30
	scale 23

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/Means_best.png
	lyxscale 30
	scale 23

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/ELBO_dmm4.png
	lyxscale 30
	scale 23

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/RamaSample_dmm4.png
	lyxscale 30
	scale 23

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/Means_dmm4.png
	lyxscale 30
	scale 23

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/ELBO_dmm5.png
	lyxscale 30
	scale 23

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/RamaSample_dmm5.png
	lyxscale 30
	scale 23

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/Means_dmm5.png
	lyxscale 30
	scale 23

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/StandardRama.png
	lyxscale 30
	scale 23

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/ELBO_dmm_1k.png
	lyxscale 30
	scale 23

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/RamaSample_dmm_1k.png
	lyxscale 30
	scale 23

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/Means_1k.png
	lyxscale 30
	scale 23

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/ELBO_dmm_k12.png
	lyxscale 30
	scale 23

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/RamaSample_dmm_k12.png
	lyxscale 30
	scale 23

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/Means_dmm_k12.png
	lyxscale 30
	scale 23

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/ELBO_onehot.png
	lyxscale 30
	scale 23

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/RamaSample_onehot.png
	lyxscale 30
	scale 23

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/Means_onehot.png
	lyxscale 30
	scale 23

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Section
Discussion
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "bibliography2"
options "unsrt"

\end_inset


\end_layout

\end_body
\end_document
